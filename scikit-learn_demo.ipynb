{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88ffd626",
   "metadata": {},
   "source": [
    "## Supervised -> Regression and Classification\n",
    "## Unsupervised -> Clustering and Association\n",
    "\n",
    "**Regression** - Ex, predictions\n",
    "\n",
    "**Classification** - Ex, classifying apples and oranges from a fruit basket\n",
    "\n",
    "**Clustering** - Ex, clustering similar objects with similar data points\n",
    "\n",
    "**Association** - Recommendation Systems\n",
    "\n",
    "## Imp. Algos\n",
    "Supervised\n",
    "- Naive-Bayes\n",
    "- Decison Trees\n",
    "- K-Nearest Neighbors(KNN)\n",
    "- Support Vector Machines (SVM)\n",
    "- Random Forest Algorithm\n",
    "\n",
    "Unsupervised\n",
    "- Clustering\n",
    "- Gaussian Mixture Models\n",
    "- Neural Networks\n",
    "- Biclustering\n",
    "- Density Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4de760f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4000a7e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>MEDV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>0.06263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.593</td>\n",
       "      <td>69.1</td>\n",
       "      <td>2.4786</td>\n",
       "      <td>1</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>391.99</td>\n",
       "      <td>9.67</td>\n",
       "      <td>22.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>0.04527</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.120</td>\n",
       "      <td>76.7</td>\n",
       "      <td>2.2875</td>\n",
       "      <td>1</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.08</td>\n",
       "      <td>20.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>0.06076</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.976</td>\n",
       "      <td>91.0</td>\n",
       "      <td>2.1675</td>\n",
       "      <td>1</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.64</td>\n",
       "      <td>23.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>0.10959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.794</td>\n",
       "      <td>89.3</td>\n",
       "      <td>2.3889</td>\n",
       "      <td>1</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>393.45</td>\n",
       "      <td>6.48</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>0.04741</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.030</td>\n",
       "      <td>80.8</td>\n",
       "      <td>2.5050</td>\n",
       "      <td>1</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>7.88</td>\n",
       "      <td>11.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>506 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0    0.00632  18.0   2.31     0  0.538  6.575  65.2  4.0900    1  296.0   \n",
       "1    0.02731   0.0   7.07     0  0.469  6.421  78.9  4.9671    2  242.0   \n",
       "2    0.02729   0.0   7.07     0  0.469  7.185  61.1  4.9671    2  242.0   \n",
       "3    0.03237   0.0   2.18     0  0.458  6.998  45.8  6.0622    3  222.0   \n",
       "4    0.06905   0.0   2.18     0  0.458  7.147  54.2  6.0622    3  222.0   \n",
       "..       ...   ...    ...   ...    ...    ...   ...     ...  ...    ...   \n",
       "501  0.06263   0.0  11.93     0  0.573  6.593  69.1  2.4786    1  273.0   \n",
       "502  0.04527   0.0  11.93     0  0.573  6.120  76.7  2.2875    1  273.0   \n",
       "503  0.06076   0.0  11.93     0  0.573  6.976  91.0  2.1675    1  273.0   \n",
       "504  0.10959   0.0  11.93     0  0.573  6.794  89.3  2.3889    1  273.0   \n",
       "505  0.04741   0.0  11.93     0  0.573  6.030  80.8  2.5050    1  273.0   \n",
       "\n",
       "     PTRATIO       B  LSTAT  MEDV  \n",
       "0       15.3  396.90   4.98  24.0  \n",
       "1       17.8  396.90   9.14  21.6  \n",
       "2       17.8  392.83   4.03  34.7  \n",
       "3       18.7  394.63   2.94  33.4  \n",
       "4       18.7  396.90   5.33  36.2  \n",
       "..       ...     ...    ...   ...  \n",
       "501     21.0  391.99   9.67  22.4  \n",
       "502     21.0  396.90   9.08  20.6  \n",
       "503     21.0  396.90   5.64  23.9  \n",
       "504     21.0  393.45   6.48  22.0  \n",
       "505     21.0  396.90   7.88  11.9  \n",
       "\n",
       "[506 rows x 14 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT', 'MEDV']\n",
    "df = pd.read_csv('datasets/housing.csv', delimiter=r\"\\s+\", names=cols)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "982f9f34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CRIM       0\n",
       "ZN         0\n",
       "INDUS      0\n",
       "CHAS       0\n",
       "NOX        0\n",
       "RM         0\n",
       "AGE        0\n",
       "DIS        0\n",
       "RAD        0\n",
       "TAX        0\n",
       "PTRATIO    0\n",
       "B          0\n",
       "LSTAT      0\n",
       "MEDV       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum() #counts number of NaN in each column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "214cc417",
   "metadata": {},
   "source": [
    "### We have 505 rows of data. So we split data for training and testing (70+30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "12dc07d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split # pretty self-explanatory import\n",
    "X = np.array(df.iloc[:,0:13]) # first 13 columns, From X, data will be splitted 70-30\n",
    "Y = np.array(df['MEDV']) # last column, From Y, data will be splitted 70-30\n",
    "x_train, x_test, y_train, y_test = train_test_split(X,Y, test_size = 0.30, random_state=5) #0.30 is 30%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d5861ec",
   "metadata": {},
   "source": [
    "### Importing KNN algo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1ba3a64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "#loading model\n",
    "Nn=KNeighborsRegressor(3) #values of k=3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d38346",
   "metadata": {},
   "source": [
    "### Model Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "be813f98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsRegressor(n_neighbors=3)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Nn.fit(x_train, y_train) #with this one line, the model has learnt everything\n",
    "# X-train -> input\n",
    "# Y-train -> output\n",
    "# <---model learns--->\n",
    "# X-test -> input given\n",
    "# Y-test -> output (which is supposed to come)\n",
    "# Y-pred ->output given (by the model after learning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38bb1ae1",
   "metadata": {},
   "source": [
    "### Model Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "48755fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = Nn.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ee230a",
   "metadata": {},
   "source": [
    "### But there's no way for us to know whether we have assumed the right k value. This is where HYPERPARAMETER TUNING comes into the picture. Using the for loop we try with 50 diff. k values and see which one has low error rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4e38051d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.97154478854566 error for k=1\n",
      "7.159484875618533 error for k=2\n",
      "7.014927171138291 error for k=3\n",
      "7.004019640065342 error for k=4\n",
      "7.036131375752027 error for k=5\n",
      "7.103650686103268 error for k=6\n",
      "7.249246229196143 error for k=7\n",
      "7.278466403768686 error for k=8\n",
      "7.490296733721186 error for k=9\n",
      "7.573928228851226 error for k=10\n",
      "7.580880154071545 error for k=11\n",
      "7.620709624858009 error for k=12\n",
      "7.702433441773159 error for k=13\n",
      "7.745706188130712 error for k=14\n",
      "7.855546909761407 error for k=15\n",
      "7.970845764140948 error for k=16\n",
      "8.00708692880329 error for k=17\n",
      "8.05951400020052 error for k=18\n",
      "8.105972848197592 error for k=19\n",
      "8.171623447622684 error for k=20\n",
      "8.208766061680672 error for k=21\n",
      "8.266010100575647 error for k=22\n",
      "8.280897264278922 error for k=23\n",
      "8.326448746059764 error for k=24\n",
      "8.38105978099617 error for k=25\n",
      "8.410954693047014 error for k=26\n",
      "8.478704509976565 error for k=27\n",
      "8.50999986845734 error for k=28\n",
      "8.538275555508479 error for k=29\n",
      "8.57421797961705 error for k=30\n",
      "8.599468444172452 error for k=31\n",
      "8.616512206922689 error for k=32\n",
      "8.615421855795727 error for k=33\n",
      "8.6394479574174 error for k=34\n",
      "8.668090456321325 error for k=35\n",
      "8.710050513540338 error for k=36\n",
      "8.718258951585424 error for k=37\n",
      "8.73453661426121 error for k=38\n",
      "8.73394194177396 error for k=39\n",
      "8.738089791196538 error for k=40\n",
      "8.747832356642228 error for k=41\n",
      "8.756251724223462 error for k=42\n",
      "8.757243221295424 error for k=43\n",
      "8.77507943271184 error for k=44\n",
      "8.790125037827208 error for k=45\n",
      "8.812499208822205 error for k=46\n",
      "8.821646387484796 error for k=47\n",
      "8.828821656839208 error for k=48\n",
      "8.82175940968693 error for k=49\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,50):\n",
    "    model = KNeighborsRegressor(i)\n",
    "    model.fit(x_train, y_train) # x-train, y-train given to study\n",
    "    y_pred = model.predict(x_test) # x-test given to predict output\n",
    "    error = sklearn.metrics.mean_squared_error(y_test, y_pred, squared=False) # y-test expected ouput for corresponding x-test\n",
    "                                                                              # y_pred predcited by model, thus giving error\n",
    "    print(str(error) + ' error for k=' + str(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "488c3b64",
   "metadata": {},
   "source": [
    "### So the best k=value is 4 with least error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "9cc9d90e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.004019640065342 error for k=4\n"
     ]
    }
   ],
   "source": [
    "final_NN = KNeighborsRegressor(4)\n",
    "final_NN.fit(x_train, y_train) # x-train, y-train given to study\n",
    "y_pred = final_NN.predict(x_test) # x-test given to predict output\n",
    "error = sklearn.metrics.mean_squared_error(y_test, y_pred, squared=False) # y-test expected ouput for corresponding x-test\n",
    "                                                                              # y_pred predcited by model, thus giving error\n",
    "print(str(error) + ' error for k=' + str(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7136021b",
   "metadata": {},
   "source": [
    "### So the model has learnt, fitted, optimized and evaluated. Now to check for results. y_pred has results given by the model based on x_test after learning x_train and y_train whereas y_test has the **actual** output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "b2e141de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted output from y_pred:<----->Actual output from y_test\n",
      "31.4500<----->37.6000\n",
      "35.1500<----->27.9000\n",
      "23.6250<----->22.6000\n",
      "11.1500<----->13.8000\n",
      "30.0500<----->35.2000\n",
      "15.4500<----->10.4000\n",
      "21.5500<----->23.9000\n",
      "33.9000<----->29.0000\n",
      "18.8250<----->22.8000\n",
      "22.6000<----->23.2000\n",
      "22.8500<----->33.2000\n",
      "27.4250<----->19.0000\n",
      "20.1000<----->20.3000\n",
      "30.0000<----->36.1000\n",
      "31.8750<----->24.4000\n",
      "19.0750<----->17.2000\n",
      "10.3750<----->17.9000\n",
      "20.9250<----->19.6000\n",
      "21.5750<----->19.7000\n",
      "10.4250<----->15.0000\n",
      "18.2750<----->8.1000\n",
      "18.0250<----->23.0000\n",
      "37.6750<----->44.8000\n",
      "20.2500<----->23.1000\n",
      "24.5250<----->32.2000\n",
      "14.1000<----->10.8000\n",
      "23.4000<----->23.1000\n",
      "18.2750<----->21.2000\n",
      "24.0750<----->22.2000\n",
      "33.8000<----->24.1000\n",
      "19.0500<----->17.3000\n",
      "16.9500<----->7.0000\n",
      "12.4250<----->12.7000\n",
      "17.5750<----->17.8000\n",
      "28.4250<----->26.4000\n",
      "18.1000<----->19.6000\n",
      "29.5500<----->25.1000\n",
      "12.6000<----->8.3000\n",
      "41.4000<----->48.8000\n",
      "31.9250<----->34.9000\n",
      "15.4750<----->13.8000\n",
      "16.8750<----->14.4000\n",
      "22.0250<----->30.1000\n",
      "13.8000<----->12.7000\n",
      "22.5750<----->27.1000\n",
      "32.4750<----->24.8000\n",
      "12.6000<----->7.0000\n",
      "19.0500<----->20.5000\n",
      "36.9000<----->21.5000\n",
      "17.0500<----->14.0000\n",
      "21.5750<----->20.4000\n",
      "22.0250<----->22.2000\n",
      "21.7000<----->21.4000\n",
      "16.7250<----->13.5000\n",
      "22.4000<----->19.4000\n",
      "23.5750<----->24.7000\n",
      "24.7000<----->43.8000\n",
      "11.7250<----->14.1000\n",
      "23.4000<----->28.6000\n",
      "22.0000<----->19.7000\n",
      "21.3000<----->16.8000\n",
      "22.7250<----->23.2000\n",
      "16.9750<----->16.2000\n",
      "36.9000<----->41.3000\n",
      "20.5000<----->22.7000\n",
      "10.9750<----->8.3000\n",
      "19.6250<----->18.4000\n",
      "24.1000<----->24.7000\n",
      "31.4500<----->21.7000\n",
      "23.2250<----->20.6000\n",
      "12.9750<----->16.7000\n",
      "21.1250<----->22.1000\n",
      "26.0250<----->19.4000\n",
      "17.3000<----->27.5000\n",
      "18.1500<----->27.9000\n",
      "44.4750<----->30.1000\n",
      "22.5250<----->17.4000\n",
      "19.1250<----->15.4000\n",
      "39.9250<----->31.0000\n",
      "17.6750<----->14.2000\n",
      "19.9000<----->19.6000\n",
      "36.5000<----->50.0000\n",
      "15.7750<----->21.7000\n",
      "13.2000<----->11.7000\n",
      "24.5250<----->19.4000\n",
      "16.8250<----->13.0000\n",
      "21.5750<----->17.5000\n",
      "12.4250<----->9.7000\n",
      "22.9750<----->20.3000\n",
      "34.5250<----->18.6000\n",
      "34.8000<----->50.0000\n",
      "20.3250<----->19.6000\n",
      "15.1000<----->21.4000\n",
      "12.5500<----->18.4000\n",
      "21.2500<----->22.6000\n",
      "29.9500<----->25.0000\n",
      "22.4000<----->15.6000\n",
      "25.5750<----->26.6000\n",
      "24.2750<----->22.4000\n",
      "20.7500<----->13.1000\n",
      "22.5000<----->23.0000\n",
      "21.6250<----->24.5000\n",
      "14.3500<----->13.1000\n",
      "44.4750<----->50.0000\n",
      "9.1000<----->8.8000\n",
      "23.7500<----->20.6000\n",
      "16.2250<----->12.1000\n",
      "36.4500<----->50.0000\n",
      "30.5500<----->24.1000\n",
      "32.6500<----->16.1000\n",
      "30.2500<----->23.9000\n",
      "36.4250<----->24.3000\n",
      "12.5750<----->13.1000\n",
      "23.5000<----->30.3000\n",
      "24.6750<----->15.2000\n",
      "20.7500<----->13.8000\n",
      "34.9500<----->26.4000\n",
      "22.3000<----->16.6000\n",
      "19.6250<----->18.9000\n",
      "25.5750<----->17.6000\n",
      "25.7250<----->18.7000\n",
      "30.6750<----->33.4000\n",
      "24.0750<----->20.7000\n",
      "23.0500<----->17.1000\n",
      "29.9500<----->23.4000\n",
      "21.5750<----->26.5000\n",
      "21.9750<----->21.4000\n",
      "22.4250<----->21.5000\n",
      "18.8250<----->19.2000\n",
      "35.1500<----->50.0000\n",
      "34.5750<----->50.0000\n",
      "21.0750<----->23.0000\n",
      "9.0750<----->10.5000\n",
      "16.8750<----->17.8000\n",
      "11.2000<----->10.9000\n",
      "19.5750<----->21.0000\n",
      "15.6500<----->13.8000\n",
      "9.0250<----->10.5000\n",
      "21.0500<----->22.2000\n",
      "33.2750<----->30.5000\n",
      "20.3250<----->19.4000\n",
      "20.7500<----->15.6000\n",
      "16.4000<----->20.2000\n",
      "19.3500<----->19.3000\n",
      "24.2250<----->34.6000\n",
      "21.5250<----->50.0000\n",
      "22.2250<----->24.0000\n",
      "21.4000<----->18.7000\n",
      "19.6250<----->19.8000\n",
      "25.9750<----->22.5000\n",
      "16.9750<----->13.3000\n",
      "18.8250<----->50.0000\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 152 is out of bounds for axis 0 with size 152",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-82-9b69da239d6f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Predicted output from y_pred:'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'<----->'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'Actual output from y_test'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m153\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'{:.4f}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'<----->'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'{:.4f}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m: index 152 is out of bounds for axis 0 with size 152"
     ]
    }
   ],
   "source": [
    "print('Predicted output from y_pred:' + '<----->' + 'Actual output from y_test')\n",
    "for i in range(0,153):\n",
    "    print('{:.4f}'.format(y_pred[i]) + '<----->' + '{:.4f}'.format(y_test[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "809c4014",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49.05629111842104"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean((y_pred-y_test) ** 2) # root mean square of error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "511bfe1b",
   "metadata": {},
   "source": [
    "## We have a 49.05 mean error for our model, which makes sense cuz we literally took a K-value with 7.0040 as error rate (*dumbazzz ;)*). We had already taken the best k-value, but still there's a lot of diff. between the predicted value and the actual test value. So what's the problem?\n",
    "\n",
    "## -->Its the MODEL. Yep, KNN is not the right model for this problem statement.\n",
    "### Lets try the same with Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "27720e5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted output from linear_y_pred:<----->Actual output from y_test\n",
      "37.3900<----->37.6000\n",
      "31.5679<----->27.9000\n",
      "27.1337<----->22.6000\n",
      "6.5512<----->13.8000\n",
      "33.6931<----->35.2000\n",
      "5.5492<----->10.4000\n",
      "27.1001<----->23.9000\n",
      "29.8298<----->29.0000\n",
      "26.4462<----->22.8000\n",
      "22.3887<----->23.2000\n",
      "32.2474<----->33.2000\n",
      "21.7489<----->19.0000\n",
      "23.4237<----->20.3000\n",
      "33.5797<----->36.1000\n",
      "28.3145<----->24.4000\n",
      "15.3650<----->17.2000\n",
      "0.1701<----->17.9000\n",
      "18.7086<----->19.6000\n",
      "14.6046<----->19.7000\n",
      "10.8026<----->15.0000\n",
      "3.1855<----->8.1000\n",
      "19.3925<----->23.0000\n",
      "38.3324<----->44.8000\n",
      "24.4046<----->23.1000\n",
      "31.9995<----->32.2000\n",
      "11.3520<----->10.8000\n",
      "24.9229<----->23.1000\n",
      "23.3921<----->21.2000\n",
      "22.7507<----->22.2000\n",
      "21.0958<----->24.1000\n",
      "16.1230<----->17.3000\n",
      "7.5354<----->7.0000\n",
      "17.5980<----->12.7000\n",
      "22.8221<----->17.8000\n",
      "29.2679<----->26.4000\n",
      "18.8053<----->19.6000\n",
      "28.3367<----->25.1000\n",
      "8.6047<----->8.3000\n",
      "41.6323<----->48.8000\n",
      "34.1975<----->34.9000\n",
      "20.1177<----->13.8000\n",
      "4.3099<----->14.4000\n",
      "29.6111<----->30.1000\n",
      "11.9215<----->12.7000\n",
      "27.2222<----->27.1000\n",
      "30.9454<----->24.8000\n",
      "-6.2647<----->7.0000\n",
      "19.9637<----->20.5000\n",
      "21.5938<----->21.5000\n",
      "13.6436<----->14.0000\n",
      "20.4985<----->20.4000\n",
      "19.9377<----->22.2000\n",
      "23.6538<----->21.4000\n",
      "13.5165<----->13.5000\n",
      "17.6443<----->19.4000\n",
      "25.2014<----->24.7000\n",
      "35.3149<----->43.8000\n",
      "15.2534<----->14.1000\n",
      "28.5100<----->28.6000\n",
      "21.8525<----->19.7000\n",
      "20.6639<----->16.8000\n",
      "26.0316<----->23.2000\n",
      "14.7163<----->16.2000\n",
      "32.3465<----->41.3000\n",
      "20.7126<----->22.7000\n",
      "12.1691<----->8.3000\n",
      "19.6099<----->18.4000\n",
      "25.1948<----->24.7000\n",
      "21.7899<----->21.7000\n",
      "21.1727<----->20.6000\n",
      "20.5707<----->16.7000\n",
      "26.6823<----->22.1000\n",
      "17.6343<----->19.4000\n",
      "18.5968<----->27.5000\n",
      "18.8646<----->27.9000\n",
      "26.1126<----->30.1000\n",
      "21.8839<----->17.4000\n",
      "15.7936<----->15.4000\n",
      "35.1229<----->31.0000\n",
      "17.9301<----->14.2000\n",
      "22.3741<----->19.6000\n",
      "39.4321<----->50.0000\n",
      "22.3586<----->21.7000\n",
      "14.7508<----->11.7000\n",
      "25.5997<----->19.4000\n",
      "17.2634<----->13.0000\n",
      "18.6474<----->17.5000\n",
      "10.0260<----->9.7000\n",
      "19.7358<----->20.3000\n",
      "17.6831<----->18.6000\n",
      "36.1822<----->50.0000\n",
      "17.6844<----->19.6000\n",
      "21.0208<----->21.4000\n",
      "19.0402<----->18.4000\n",
      "24.8101<----->22.6000\n",
      "28.1227<----->25.0000\n",
      "12.3997<----->15.6000\n",
      "22.7785<----->26.6000\n",
      "21.0432<----->22.4000\n",
      "13.3715<----->13.1000\n",
      "22.9950<----->23.0000\n",
      "21.6510<----->24.5000\n",
      "14.2948<----->13.1000\n",
      "42.9844<----->50.0000\n",
      "1.8887<----->8.8000\n",
      "22.0456<----->20.6000\n",
      "18.3099<----->12.1000\n",
      "22.3247<----->50.0000\n",
      "29.2639<----->24.1000\n",
      "18.4094<----->16.1000\n",
      "27.8731<----->23.9000\n",
      "24.5829<----->24.3000\n",
      "20.2883<----->13.1000\n",
      "33.0103<----->30.3000\n",
      "19.6981<----->15.2000\n",
      "12.8886<----->13.8000\n",
      "22.6587<----->26.4000\n",
      "18.3919<----->16.6000\n",
      "19.5948<----->18.9000\n",
      "16.3862<----->17.6000\n",
      "21.7491<----->18.7000\n",
      "35.4807<----->33.4000\n",
      "22.2260<----->20.7000\n",
      "20.4460<----->17.1000\n",
      "24.5924<----->23.4000\n",
      "25.3763<----->26.5000\n",
      "20.4210<----->21.4000\n",
      "23.0493<----->21.5000\n",
      "23.4528<----->19.2000\n",
      "41.1019<----->50.0000\n",
      "37.8471<----->50.0000\n",
      "27.5238<----->23.0000\n",
      "12.5500<----->10.5000\n",
      "16.1358<----->17.8000\n",
      "18.2712<----->10.9000\n",
      "21.6863<----->21.0000\n",
      "15.7086<----->13.8000\n",
      "5.6663<----->10.5000\n",
      "24.0994<----->22.2000\n",
      "30.5652<----->30.5000\n",
      "23.0495<----->19.4000\n",
      "18.1618<----->15.6000\n",
      "16.1549<----->20.2000\n",
      "21.7177<----->19.3000\n",
      "35.0680<----->34.6000\n",
      "23.2009<----->50.0000\n",
      "30.2206<----->24.0000\n",
      "18.2331<----->18.7000\n",
      "22.2974<----->19.8000\n",
      "29.3267<----->22.5000\n",
      "13.6077<----->13.3000\n",
      "31.6703<----->50.0000\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 152 is out of bounds for axis 0 with size 152",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-86-3fce6f655444>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Predicted output from linear_y_pred:'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'<----->'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'Actual output from y_test'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m153\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'{:.4f}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlinear_y_pred\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'<----->'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'{:.4f}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m: index 152 is out of bounds for axis 0 with size 152"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "#load model\n",
    "linear_model = linear_model.LinearRegression()\n",
    "\n",
    "#we've already fitted our data 70-30. Let's use that\n",
    "linear_model.fit(x_train, y_train)\n",
    "linear_y_pred = linear_model.predict(x_test)\n",
    "\n",
    "#lets compare values\n",
    "print('Predicted output from linear_y_pred:' + '<----->' + 'Actual output from y_test')\n",
    "for i in range(0,153):\n",
    "    print('{:.4f}'.format(linear_y_pred[i]) + '<----->' + '{:.4f}'.format(y_test[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "68520395",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30.697037704088633"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean((linear_y_pred-y_test) ** 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf06c38",
   "metadata": {},
   "source": [
    "### Better than 49.05\n",
    "\n",
    "**In this case, Linear Regression is better than KNN but we can improve that too by using better models**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
